{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "PROJECT_ROOT = '/'\n",
    "\n",
    "sys.path.append(PROJECT_ROOT)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = {'groups_desc': 'data/small_group_description.csv',\n",
    "    'train_x': 'data/transactions_train.csv',\n",
    "    'test_x': 'data/transactions_test.csv',\n",
    "    'train_target': 'data/train_target.csv',\n",
    "    'test_target': 'data/test.csv'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading groups_desc...\n",
      "Reading train_x...\n",
      "Reading test_x...\n",
      "Reading train_target...\n",
      "Reading test_target...\n",
      "Validation split: by clientID\n",
      "CPU times: user 12.8 s, sys: 6.13 s, total: 18.9 s\n",
      "Wall time: 22.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ds = DataSource(conf)\n",
    "ds.read_data()\n",
    "ds.validation_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: groups_desc, shape: (204, 2)\n",
      "Dataset: train_x, shape: (21295142, 4)\n",
      "Dataset: test_x, shape: (17667328, 4)\n",
      "Dataset: train_target, shape: (24145, 1)\n",
      "Dataset: test_target, shape: (20000, 1)\n",
      "Dataset: valid_x, shape: (5155435, 4)\n",
      "Dataset: valid_target, shape: (5855, 2)\n"
     ]
    }
   ],
   "source": [
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = ds.get_data('train_target')\n",
    "train_target.set_index('client_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>small_group</th>\n",
       "      <th>small_group_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>Антиквариат</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>Строительные подрядчики</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>Услуги химчистки (ковры)</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>Велоспорт (покупка велосипеда  или комплектующих)</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Автодилеры (мотоциклы)</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Бассейны</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Электромонтажные работы и оборудование (свет)</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>Электромонтажные работы и оборудование (сигнал...</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>Похоронные услуги</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>Кемпинг (оборудование)</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>Услуги хранения</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>Клининг</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>Нумизматика</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>Сервисные центры по ремонту техники и некоторы...</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>Обслуживание существующего автомобиля (эвакуация)</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>Водный спорт (яхты)</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>Онлайн-товары</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>Архитектурные и инженерно-геодезические услуги</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>Консультационные и нотариальные услуги</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>Центры развития и детские сады</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>Окна и двери</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>Офисная мебель</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>Особое оборудование</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>Металлопрокат</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>Строительные материалы (двери)</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>Политический краудфандинг</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>Винодельни и пивоварни</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>Санатории, парки, прогулки на природе</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>Камины и печи</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>Водный спорт (лодки и дайвинг)</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>Костюмы и униформа</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>Прочие отели (аппартаменты)</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>Натяжные потолки</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>Участие в автомобильных организациях</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>Стенографические услуги</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>Бильярд</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>Аренда трейлеров или картинг</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>Бытовая техника (электробритвы)</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>Остеопаты</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>Дом на колесах</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>Услуги починки (кондиционеры и холодильники)</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>Медицинское оборудование (слуховые аппараты)</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>Аренда оборудования для грузовиков и трейлеров</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>Униформа и костюмы (прокат)</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>Снегоходы</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Услуги починки (мебель)</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Обслуживание существующего автомобиля (утилиза...</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Ортопедия</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Наружная реклама и плоттерная резка</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Услуги починки (металлические изделия)</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>Телеграф</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>Мануальные терапевты</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>Скорая помощь</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>Бетонные работы</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           small_group  small_group_code\n",
       "150                                        Антиквариат               150\n",
       "151                            Строительные подрядчики               151\n",
       "152                           Услуги химчистки (ковры)               152\n",
       "153  Велоспорт (покупка велосипеда  или комплектующих)               153\n",
       "154                             Автодилеры (мотоциклы)               154\n",
       "155                                           Бассейны               155\n",
       "156      Электромонтажные работы и оборудование (свет)               156\n",
       "157  Электромонтажные работы и оборудование (сигнал...               157\n",
       "158                                  Похоронные услуги               158\n",
       "159                             Кемпинг (оборудование)               159\n",
       "160                                    Услуги хранения               160\n",
       "161                                            Клининг               161\n",
       "162                                        Нумизматика               162\n",
       "163  Сервисные центры по ремонту техники и некоторы...               163\n",
       "164  Обслуживание существующего автомобиля (эвакуация)               164\n",
       "165                                Водный спорт (яхты)               165\n",
       "166                                      Онлайн-товары               166\n",
       "167     Архитектурные и инженерно-геодезические услуги               167\n",
       "168             Консультационные и нотариальные услуги               168\n",
       "169                     Центры развития и детские сады               169\n",
       "170                                       Окна и двери               170\n",
       "171                                     Офисная мебель               171\n",
       "172                                Особое оборудование               172\n",
       "173                                      Металлопрокат               173\n",
       "174                     Строительные материалы (двери)               174\n",
       "175                          Политический краудфандинг               175\n",
       "176                             Винодельни и пивоварни               176\n",
       "177              Санатории, парки, прогулки на природе               177\n",
       "178                                      Камины и печи               178\n",
       "179                     Водный спорт (лодки и дайвинг)               179\n",
       "180                                 Костюмы и униформа               180\n",
       "181                        Прочие отели (аппартаменты)               181\n",
       "182                                   Натяжные потолки               182\n",
       "183               Участие в автомобильных организациях               183\n",
       "184                            Стенографические услуги               184\n",
       "185                                            Бильярд               185\n",
       "186                       Аренда трейлеров или картинг               186\n",
       "187                    Бытовая техника (электробритвы)               187\n",
       "188                                          Остеопаты               188\n",
       "189                                     Дом на колесах               189\n",
       "190       Услуги починки (кондиционеры и холодильники)               190\n",
       "191       Медицинское оборудование (слуховые аппараты)               191\n",
       "192     Аренда оборудования для грузовиков и трейлеров               192\n",
       "193                        Униформа и костюмы (прокат)               193\n",
       "194                                          Снегоходы               194\n",
       "195                            Услуги починки (мебель)               195\n",
       "196  Обслуживание существующего автомобиля (утилиза...               196\n",
       "197                                          Ортопедия               197\n",
       "198                Наружная реклама и плоттерная резка               198\n",
       "199             Услуги починки (металлические изделия)               199\n",
       "200                                           Телеграф               200\n",
       "201                               Мануальные терапевты               201\n",
       "202                                      Скорая помощь               202\n",
       "203                                    Бетонные работы               203"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.get_data('groups_desc')[150:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   client_id  trans_date  small_group  amount_rur\n",
      "0       3694          26            1      10.006\n",
      "1       3694          29            3      54.955\n",
      "2       3694          31            1      10.945\n",
      "3       3694          34           36      61.721\n",
      "4       3694          36           25       4.579\n"
     ]
    }
   ],
   "source": [
    "train_x = ds.get_data('train_x')\n",
    "print(train_x.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            s6\n",
      "bins          \n",
      "0     0.015202\n",
      "1     0.007810\n",
      "2     0.000329\n",
      "3     0.017969\n"
     ]
    }
   ],
   "source": [
    "gr6 = train_x.groupby(['client_id']).apply(lambda x: pd.Series({'s6':\n",
    "                    (x['small_group']==169).sum()}))\n",
    "\n",
    "#gr.set_index('client_id', inplace=True)\n",
    "joined = train_target.join(gr6)\n",
    "zero =  joined.groupby('bins').agg({'s6':'mean'})\n",
    "print(zero.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x['month_number'] = train_x['trans_date']//30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24145"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_x.groupby(['client_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           bins  client_id  trans_date  small_group  amount_rur  month_number\n",
      "client_id                                                                    \n",
      "1046          0       3694         710           80      30.362            23\n",
      "34089         2      34445         669            9     101.208            22\n",
      "34848         1      32728         502           24     665.480            16\n",
      "47076         3      19350          48           11      22.486             1\n",
      "10938         2       6767         593            1      82.963            19\n",
      "...         ...        ...         ...          ...         ...           ...\n",
      "36716         2      13026         709           24     107.086            23\n",
      "14303         1      38817         535            3      21.564            17\n",
      "22301         2      31317         165            1      16.211             5\n",
      "25731         0      46358         561            1      10.199            18\n",
      "16820         3       4323         506            1      60.258            16\n",
      "\n",
      "[24145 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "#print(train_target.head())\n",
    "print(train_target.join(train_x))\n",
    "#train_x.groupby(['client_id'])[\"trans_date\"].agg({\"tr_c\": \"count\"}).tr_c.max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version. Use                 named aggregation instead.\n",
      "\n",
      "    >>> grouper.agg(name_1=func_1, name_2=func_2)\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  s1\n",
      "client_id           \n",
      "4          28404.121\n",
      "6          15720.739\n",
      "10         34419.365\n",
      "11         26789.404\n",
      "13         17337.467\n",
      "                s1\n",
      "bins              \n",
      "0     46951.066337\n",
      "1     62098.233179\n",
      "2     28172.588712\n",
      "3     60398.480530\n"
     ]
    }
   ],
   "source": [
    "gr1 = train_x.groupby(['client_id'])[\"amount_rur\"].agg({\"s1\": \"sum\"})\n",
    "print(gr1.head())\n",
    "#gr.set_index('client_id')\n",
    "joined = train_target.join(gr1)\n",
    "zero =  joined.groupby('bins').agg({'s1':'mean'})\n",
    "print(zero.head())\n",
    "#print(joined[joined[\"client_id\"]==3694].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version. Use                 named aggregation instead.\n",
      "\n",
      "    >>> grouper.agg(name_1=func_1, name_2=func_2)\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               s2\n",
      "bins             \n",
      "0     2589.771139\n",
      "1     3578.836228\n",
      "2     1581.059080\n",
      "3     3319.801815\n"
     ]
    }
   ],
   "source": [
    "gr2 = train_x.groupby(['client_id'])[\"amount_rur\"].agg({\"s2\": \"max\"})\n",
    "joined = train_target.join(gr2)\n",
    "zero =  joined.groupby('bins').agg({'s2':'mean'})\n",
    "print(zero.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version. Use                 named aggregation instead.\n",
      "\n",
      "    >>> grouper.agg(name_1=func_1, name_2=func_2)\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            s3\n",
      "bins          \n",
      "0     0.294786\n",
      "1     0.557962\n",
      "2     0.196993\n",
      "3     0.396317\n"
     ]
    }
   ],
   "source": [
    "gr3 = train_x.groupby(['client_id'])[\"amount_rur\"].agg({\"s3\": \"min\"})\n",
    "joined = train_target.join(gr3)\n",
    "zero =  joined.groupby('bins').agg({'s3':'mean'})\n",
    "print(zero.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             c4\n",
      "bins           \n",
      "0     47.302038\n",
      "1     47.874875\n",
      "2     44.124609\n",
      "3     48.889878\n"
     ]
    }
   ],
   "source": [
    "grouped_by_group = train_x.groupby(['client_id', 'small_group'], as_index = False)['amount_rur'].agg({'c4':'min'})\n",
    "gr4  = grouped_by_group.loc[grouped_by_group.groupby('client_id')['c4'].idxmax()][['client_id','small_group']]\n",
    "gr4.columns = ['client_id', 'c4']\n",
    "gr4.set_index('client_id', inplace=True)\n",
    "\n",
    "joined = train_target.join(gr4)\n",
    "zero =  joined.groupby('bins').agg({'c4':'mean'})\n",
    "print(zero.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            c5\n",
      "bins          \n",
      "0     7.071834\n",
      "1     5.203390\n",
      "2     7.260412\n",
      "3     6.230630\n"
     ]
    }
   ],
   "source": [
    "grouped_by_group = train_x.groupby(['client_id', 'small_group'], as_index = False)['amount_rur'].agg({'c5':'sum'})\n",
    "gr5  = grouped_by_group.loc[grouped_by_group.groupby('client_id')['c5'].idxmax()][['client_id','small_group']]\n",
    "gr5.columns = ['client_id', 'c5']\n",
    "gr5.set_index('client_id', inplace=True)\n",
    "\n",
    "joined = train_target.join(gr5)\n",
    "zero =  joined.groupby('bins').agg({'c5':'mean'})\n",
    "print(zero.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             s6\n",
      "bins           \n",
      "0     36.456231\n",
      "1     53.253074\n",
      "2     29.438519\n",
      "3     41.931091\n"
     ]
    }
   ],
   "source": [
    "gr6 = train_x.groupby(['client_id']).apply(lambda x: pd.Series({'s6':\n",
    "                    (x['small_group']==4).sum()}))\n",
    "\n",
    "#gr.set_index('client_id', inplace=True)\n",
    "joined = train_target.join(gr6)\n",
    "zero =  joined.groupby('bins').agg({'s6':'mean'})\n",
    "print(zero.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             s11\n",
      "bins            \n",
      "0     892.768460\n",
      "1     859.832669\n",
      "2     889.435226\n",
      "3     885.795912\n"
     ]
    }
   ],
   "source": [
    "gr11 = train_x.groupby(['client_id'])[\"trans_date\"].agg({\"s11\": \"count\"})\n",
    "joined = train_target.join(gr11)\n",
    "zero =  joined.groupby('bins').agg({'s11':'mean'})\n",
    "print(zero.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = train_x.groupby(['client_id', 'month_number'], as_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client_per_month_spendings = train_x.groupby(['client_id', 'month_number']).agg({\"amount_rur\": \"sum\"}).groupby('client_id').agg({'amount_rur':'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           freq_group\n",
      "client_id            \n",
      "4                   1\n",
      "6                   1\n",
      "10                  1\n",
      "11                  1\n",
      "13                 11\n"
     ]
    }
   ],
   "source": [
    "grouped_by_group = train_x.groupby(['client_id', 'small_group'], as_index = False)['small_group'].agg({'freq':'count'})\n",
    "client_per_max_frequent_category  = grouped_by_group.loc[grouped_by_group.groupby('client_id')['freq'].idxmax()][['client_id','small_group']]\n",
    "client_per_max_frequent_category.columns = ['client_id', 'freq_group']\n",
    "client_per_max_frequent_category.set_index('client_id', inplace=True)\n",
    "print(client_per_max_frequent_category.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2765.900111078898\n",
      "553.1800222157797\n"
     ]
    }
   ],
   "source": [
    "# Вычислием среднюю максимальную транзакцию по клиентам. Далее найдем среднее отклонение максим транзакций по клиентам. \n",
    "# Это позволит найти \"большие\" транзакции , как mean + std. у нас не гаусово распределение, но все же оперделим значение \"большой\" транзакции \n",
    "# именно так.\n",
    "grouped_by_max = train_x.groupby(['client_id'], as_index = False).agg({'amount_rur':'max'})\n",
    "print(grouped_by_max.agg({'amount_rur':'mean'})['amount_rur'] )\n",
    "large_transactions = grouped_by_max.agg({'amount_rur':'mean'})['amount_rur'] /5\n",
    "print(large_transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20288"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_x[train_x['amount_rur'] > large_transactions]['client_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8787477259259386\n"
     ]
    }
   ],
   "source": [
    "grouped_by_min = train_x.groupby(['client_id'], as_index = False).agg({'amount_rur':'min'})\n",
    "small_transactions = grouped_by_min.agg({'amount_rur':'mean'})['amount_rur'] + grouped_by_min.agg({'amount_rur':'std'})['amount_rur']\n",
    "print(small_transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21109"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_x[train_x['amount_rur'] < small_transactions]['client_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_per_small_count = train_x[train_x['amount_rur'] < small_transactions].groupby(['client_id'])['trans_date'].agg({'small_num':'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_per_large_count = train_x[train_x['amount_rur'] > large_transactions].groupby(['client_id'])['trans_date'].agg({'large_num':'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_trans_per_month = train_x.groupby(['client_id', 'month_number'])['amount_rur'].agg({\"tran_num_mean\": \"count\"}).groupby('client_id').agg({'tran_num_mean':'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                max\n",
      "client_id          \n",
      "4          1341.802\n",
      "6           315.781\n",
      "10          654.893\n",
      "11         2105.058\n",
      "13         1190.322\n"
     ]
    }
   ],
   "source": [
    "client_max = train_x.groupby(['client_id'])['amount_rur'].agg({\"max\": \"max\"})\n",
    "print(client_max.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24145, 1)\n",
      "(24145, 1)\n",
      "(24145, 1)\n",
      "(21109, 1)\n",
      "(20288, 1)\n"
     ]
    }
   ],
   "source": [
    "print(client_per_month_spendings.shape)\n",
    "print(client_per_max_frequent_category.shape)\n",
    "print(clean_trans_per_month.shape)\n",
    "print(client_per_small_count.shape)\n",
    "print(client_per_large_count.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24145\n",
      "                  s1        s2     s3  c4  c5\n",
      "client_id                                    \n",
      "4          28404.121  1341.802  0.043   2   1\n",
      "6          15720.739   315.781  0.045  80   1\n",
      "10         34419.365   654.893  0.045  23   1\n",
      "11         26789.404  2105.058  0.388  66  88\n",
      "13         17337.467  1190.322  0.043  83  11\n",
      "14         26622.629  1167.291  0.043   5   1\n",
      "17         58337.998  5692.843  0.028  54   1\n",
      "19         46941.495  2049.338  0.259  26   1\n",
      "20         79997.006  3213.706  0.043  73  13\n",
      "25         77245.103  2564.078  0.647  65   1\n"
     ]
    }
   ],
   "source": [
    "print(len(gr1))\n",
    "res_df = gr1.join(gr2).join(gr3).join(gr4).join(gr5)\n",
    "res_df.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "print(res_df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['amount_rur', 'max', 'tran_num_mean', 'small_num', 'large_num'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-7573b7f2423b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcolumn_names_to_normalize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"amount_rur\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"max\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tran_num_mean\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"small_num\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"large_num\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn_names_to_normalize\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mmin_max_scaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mx_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin_max_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2979\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2980\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2981\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2983\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[1;32m   1269\u001b[0m                 \u001b[0;31m# When setting, missing keys are not allowed, even with .loc:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1270\u001b[0m                 \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"raise_missing\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_setter\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1271\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1272\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1273\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m         self._validate_read_indexer(\n\u001b[0;32m-> 1078\u001b[0;31m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1079\u001b[0m         )\n\u001b[1;32m   1080\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1161\u001b[0m                 raise KeyError(\n\u001b[1;32m   1162\u001b[0m                     \"None of [{key}] are in the [{axis}]\".format(\n\u001b[0;32m-> 1163\u001b[0;31m                         \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1164\u001b[0m                     )\n\u001b[1;32m   1165\u001b[0m                 )\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['amount_rur', 'max', 'tran_num_mean', 'small_num', 'large_num'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "column_names_to_normalize = [\"amount_rur\", \"max\", \"tran_num_mean\", \"small_num\", \"large_num\"]\n",
    "x = res_df[column_names_to_normalize].values\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "\n",
    "df_temp = pd.DataFrame(x_scaled, columns=column_names_to_normalize, index = res_df.index)\n",
    "res_df[column_names_to_normalize] = df_temp\n",
    "\n",
    "print(res_df.head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-c92f3a4b8fd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Ds' is not defined"
     ]
    }
   ],
   "source": [
    "train_dataset = Ds(data = res_df, labels = train_target)\n",
    "print(len(train_dataset))\n",
    "train_loader = DataLoader(train_dataset, batch_size=1000, shuffle=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_featured_data_v2(df):\n",
    "    gr_by_client = df.groupby(['client_id'])\n",
    "    gr1 = gr_by_client[\"amount_rur\"].agg({\"s1\": \"sum\"})\n",
    "    g\n",
    "    r2 = gr_by_client[\"amount_rur\"].agg({\"s2\": \"max\"}) \n",
    "    gr3 = gr_by_client[\"amount_rur\"].agg({\"s3\": \"min\"})\n",
    "\n",
    "    gr4_by_group = df.groupby(['client_id', 'small_group'], as_index = False)['amount_rur'].agg({'s4':'min'})\n",
    "    gr4  = gr4_by_group.loc[gr4_by_group.groupby('client_id')['s4'].idxmax()][['client_id','small_group']]\n",
    "    gr4.columns = ['client_id', 's4']\n",
    "    gr4.set_index('client_id', inplace=True)\n",
    "\n",
    "    \n",
    "    gr5_by_group = df.groupby(['client_id', 'small_group'], as_index = False)['amount_rur'].agg({'s5':'sum'})\n",
    "    gr5  = gr5_by_group.loc[gr5_by_group.groupby('client_id')['s5'].idxmax()][['client_id','small_group']]\n",
    "    gr5.columns = ['client_id', 's5']\n",
    "    gr5.set_index('client_id', inplace=True)\n",
    "    \n",
    "    gr6 = train_x.groupby(['client_id']).apply(lambda x: pd.Series({'s6':\n",
    "                    (x['small_group']==4).sum() + 0.000001}))\n",
    "\n",
    "    gr7 = train_x.groupby(['client_id']).apply(lambda x: pd.Series({'s7':\n",
    "                    (x['small_group']==27).sum() + 0.000001}))\n",
    "    \n",
    "    gr8 = train_x.groupby(['client_id']).apply(lambda x: pd.Series({'s8':\n",
    "                    (x['small_group']==61).sum() + 0.000001}))\n",
    "    \n",
    "    gr9 = train_x.groupby(['client_id']).apply(lambda x: pd.Series({'s9':\n",
    "                    (x['small_group']==77).sum() + 0.000001}))\n",
    "    \n",
    "    gr10 = train_x.groupby(['client_id']).apply(lambda x: pd.Series({'s10':\n",
    "                    (x['small_group']==86).sum() + 0.000001}))\n",
    "    \n",
    "    res = gr1.join(gr2).join(gr3).join(gr4).join(gr5).join(gr6).join(gr7).join(gr8).join(gr9).join(gr10)\n",
    "    res.fillna(0, inplace=True)\n",
    "    return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_featured_data(df):\n",
    "    df['month_number'] = df['trans_date']//30\n",
    "    per_month = df.groupby(['client_id', 'month_number']).agg({\"amount_rur\": \"sum\"}).groupby('client_id').agg({'amount_rur':'mean'})\n",
    "    #print(per_month.head())\n",
    "    large_count = df[df['amount_rur'] > 500].groupby(['client_id'])['trans_date'].agg({'large_num':'count'})\n",
    "    #print(large_count.head())\n",
    "    small_count = df[df['amount_rur'] < 1].groupby(['client_id'])['trans_date'].agg({'small_num':'count'})\n",
    "    #print(small_count.head())\n",
    "    trans_per_month = df.groupby(['client_id', 'month_number'])['amount_rur'].agg({\"tran_num_mean\": \"count\"}).groupby('client_id').agg({'tran_num_mean':'mean'})\n",
    "    #print(trans_per_month.head())\n",
    "    client_max = df.groupby(['client_id'])['amount_rur'].agg({\"max\": \"max\"})\n",
    "    #print(client_max.head())\n",
    "    res = per_month.join(client_max).join(trans_per_month).join(small_count).join(large_count)\n",
    "    res.fillna(0, inplace=True)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 s1        s2        s3        s4        s5        s6\n",
      "client_id                                                            \n",
      "4         -0.236386  0.176500  0.042200 -0.084528 -0.029608 -0.002745\n",
      "6          0.170438 -0.093678 -0.086125 -0.022603 -0.010675 -0.008973\n",
      "10        -0.126935  0.085155 -0.000104 -0.063330 -0.023186 -0.004688\n",
      "11         0.115190 -0.252753  0.420266 -0.025610 -0.004034 -0.017625\n",
      "13         0.188682 -0.002339  0.016541 -0.054697 -0.018720 -0.008007\n",
      "14        -0.221520 -0.001179 -0.032795 -0.043680 -0.012274 -0.006022\n",
      "17         0.035120 -0.015058 -0.046525 -0.043534  0.030930  0.070535\n",
      "19        -0.110461  0.205258  0.052837 -0.057309  0.073003 -0.005482\n",
      "20         0.136331 -0.123140 -0.018508 -0.028817 -0.010196 -0.008723\n",
      "25         0.092900 -0.039044 -0.050881  0.059757  0.006801 -0.007166\n",
      "27         0.113123 -0.044470 -0.063369 -0.034145 -0.009134 -0.007959\n",
      "28         0.029291 -0.078643 -0.074330 -0.026212 -0.011471  0.000663\n",
      "31         0.641751 -0.033641 -0.077655 -0.036925 -0.014167 -0.007701\n",
      "32         0.144899  0.028385 -0.033775 -0.050547 -0.014037 -0.006319\n",
      "33         0.145578 -0.011117 -0.024145 -0.046137 -0.011683 -0.006880\n",
      "34        -0.179454 -0.010009 -0.031330 -0.042803 -0.011531  0.002380\n",
      "36         0.129182  0.028188 -0.033354 -0.050840 -0.014105 -0.006431\n",
      "37         0.172116  0.052808 -0.010383  0.092752  0.005801 -0.006384\n",
      "38         0.030729  0.019362 -0.018157  0.114206 -0.016763 -0.006425\n",
      "39         0.024570  0.001984 -0.039599 -0.044089  0.008057 -0.005309\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "features = ['s1', 's2', 's3','s4', 's5','s6', 's7', 's8', 's9', 's10']\n",
    "# Separating out the features\n",
    "x = processed.loc[:, features].values\n",
    "y = processed.index.values\n",
    "\n",
    "\n",
    "pca = PCA(n_components=6)\n",
    "components = pca.fit_transform(x)\n",
    "pca_processed = pd.DataFrame(data = components\n",
    "             , columns = ['s1', 's2', 's3','s4', 's5','s6'])\n",
    "pca_processed['client_id'] = y\n",
    "pca_processed.set_index('client_id', inplace=True)\n",
    "\n",
    "print(pca_processed.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(column_names_to_normalize, df):\n",
    "    x = df[column_names_to_normalize].values\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(x)\n",
    "    \n",
    "    df_temp = pd.DataFrame(x_scaled, columns=column_names_to_normalize, index = df.index)\n",
    "    df[column_names_to_normalize] = df_temp\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden0 = nn.Linear(10, 8)\n",
    "        self.hidden1 = nn.Linear(8, 16)\n",
    "        self.hidden2 = nn.Linear(16, 32)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm1d(16)\n",
    "        self.output = nn.Linear(32, 4)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden0(x)) \n",
    "        x = F.relu(self.bn1(self.hidden1(x))) \n",
    "        x = F.relu(self.hidden2(x))\n",
    "        return F.log_softmax(self.output(x))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "\n",
    "class Ds(Dataset):\n",
    "    \n",
    "    def __init__(self, data, labels):\n",
    "        self.data = labels.join(data)\n",
    "        print(self.data.head(30))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data.iloc[index, 1:]\n",
    "        y = self.data.iloc[index, 0]\n",
    "\n",
    "        return torch.tensor(x), torch.tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(processed.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version. Use                 named aggregation instead.\n",
      "\n",
      "    >>> grouper.agg(name_1=func_1, name_2=func_2)\n",
      "\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version. Use                 named aggregation instead.\n",
      "\n",
      "    >>> grouper.agg(name_1=func_1, name_2=func_2)\n",
      "\n",
      "  after removing the cwd from sys.path.\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version. Use                 named aggregation instead.\n",
      "\n",
      "    >>> grouper.agg(name_1=func_1, name_2=func_2)\n",
      "\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  s1        s2     s3  s4  s5         s6        s7         s8  \\\n",
      "client_id                                                                       \n",
      "4          28404.121  1341.802  0.043   2   1  93.000001  0.000001   0.000001   \n",
      "6          15720.739   315.781  0.045  80   1  10.000001  0.000001   0.000001   \n",
      "10         34419.365   654.893  0.045  23   1  65.000001  0.000001   0.000001   \n",
      "11         26789.404  2105.058  0.388  66  88  23.000001  0.000001   2.000001   \n",
      "13         17337.467  1190.322  0.043  83  11  45.000001  0.000001   0.000001   \n",
      "14         26622.629  1167.291  0.043   5   1  39.000001  0.000001   1.000001   \n",
      "17         58337.998  5692.843  0.028  54   1  34.000001  2.000001   9.000001   \n",
      "19         46941.495  2049.338  0.259  26   1  98.000001  0.000001  21.000001   \n",
      "20         79997.006  3213.706  0.043  73  13  10.000001  0.000001   0.000001   \n",
      "25         77245.103  2564.078  0.647  65   1  22.000001  0.000001   4.000001   \n",
      "\n",
      "                 s9       s10  \n",
      "client_id                      \n",
      "4          0.000001  0.000001  \n",
      "6          0.000001  0.000001  \n",
      "10         0.000001  0.000001  \n",
      "11         0.000001  0.000001  \n",
      "13         0.000001  0.000001  \n",
      "14         0.000001  0.000001  \n",
      "17         9.000001  1.000001  \n",
      "19         0.000001  0.000001  \n",
      "20         0.000001  1.000001  \n",
      "25         0.000001  1.000001  \n"
     ]
    }
   ],
   "source": [
    "df = train_x\n",
    "gr_by_client = df.groupby(['client_id'])\n",
    "gr1 = gr_by_client[\"amount_rur\"].agg({\"s1\": \"sum\"})\n",
    "gr2 = gr_by_client[\"amount_rur\"].agg({\"s2\": \"max\"}) \n",
    "gr3 = gr_by_client[\"amount_rur\"].agg({\"s3\": \"min\"})\n",
    "\n",
    "gr4_by_group = df.groupby(['client_id', 'small_group'], as_index = False)['amount_rur'].agg({'s4':'min'})\n",
    "gr4  = gr4_by_group.loc[gr4_by_group.groupby('client_id')['s4'].idxmax()][['client_id','small_group']]\n",
    "gr4.columns = ['client_id', 's4']\n",
    "gr4.set_index('client_id', inplace=True)\n",
    "\n",
    "    \n",
    "gr5_by_group = df.groupby(['client_id', 'small_group'], as_index = False)['amount_rur'].agg({'s5':'sum'})\n",
    "gr5  = gr5_by_group.loc[gr5_by_group.groupby('client_id')['s5'].idxmax()][['client_id','small_group']]\n",
    "gr5.columns = ['client_id', 's5']\n",
    "gr5.set_index('client_id', inplace=True)\n",
    "    \n",
    "gr6 = train_x.groupby(['client_id']).apply(lambda x: pd.Series({'s6':\n",
    "                    (x['small_group']==4).sum() + 0.000001}))\n",
    "\n",
    "gr7 = train_x.groupby(['client_id']).apply(lambda x: pd.Series({'s7':\n",
    "                    (x['small_group']==27).sum() + 0.000001}))\n",
    "    \n",
    "gr8 = train_x.groupby(['client_id']).apply(lambda x: pd.Series({'s8':\n",
    "                    (x['small_group']==61).sum() + 0.000001}))\n",
    "    \n",
    "gr9 = train_x.groupby(['client_id']).apply(lambda x: pd.Series({'s9':\n",
    "                    (x['small_group']==77).sum() + 0.000001}))\n",
    "    \n",
    "gr10 = train_x.groupby(['client_id']).apply(lambda x: pd.Series({'s10':\n",
    "                    (x['small_group']==86).sum() + 0.000001}))\n",
    "    \n",
    "res = gr1.join(gr2).join(gr3).join(gr4).join(gr5).join(gr6).join(gr7).join(gr8).join(gr9).join(gr10)\n",
    "res.fillna(0, inplace=True)\n",
    "print(res.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           bins        s1        s2        s3        s4        s5        s6\n",
      "client_id                                                                  \n",
      "1046          0 -0.221349 -0.074568 -0.055947  0.052967 -0.006222 -0.007138\n",
      "34089         2 -0.007030 -0.006213 -0.042858 -0.042787 -0.016790 -0.006694\n",
      "34848         1 -0.143032  0.005832 -0.032920 -0.045435 -0.017777 -0.006340\n",
      "47076         3 -0.132098  0.025297 -0.019395  0.011242 -0.018466 -0.006074\n",
      "10938         2 -0.007559 -0.124109 -0.091787 -0.010345 -0.008566 -0.008870\n",
      "42965         1  0.145778  0.031268 -0.019183  0.092938 -0.007810 -0.006869\n",
      "21594         0 -0.079850  0.077540 -0.004460 -0.055048 -0.007715 -0.005493\n",
      "7952          1  0.144882  0.028339 -0.033892 -0.050882 -0.014093 -0.006483\n",
      "33810         0  0.029704  0.006959 -0.038432 -0.045973 -0.017242  0.010567\n",
      "11061         2 -0.221711 -0.044365 -0.050780 -0.033735 -0.014194 -0.006460\n",
      "30905         0 -0.174687 -0.061380 -0.059152 -0.022226  0.006821 -0.007909\n",
      "29440         3 -0.136993  0.149031  0.028928 -0.056357  0.051855 -0.006097\n",
      "48434         0  0.251931 -0.462548  0.705932 -0.095080 -0.009973 -0.025345\n",
      "17276         3  0.192614  0.041892 -0.021559  0.032824 -0.018877 -0.005812\n",
      "34732         3  0.088718  0.052451 -0.002446  0.149134  0.031034 -0.007327\n",
      "34843         2 -0.137533  0.055322 -0.012183 -0.056758 -0.021090 -0.005062\n",
      "24284         1  0.035754  0.082665 -0.000633 -0.001875 -0.021820 -0.003673\n",
      "2409          2 -0.143428 -0.084116 -0.071066 -0.031311 -0.011449 -0.007249\n",
      "30746         1 -0.127630 -0.042644  0.097353 -0.058471 -0.007326 -0.005585\n",
      "21766         1  0.261376  0.028132 -0.017843  0.160818  0.087738 -0.008789\n",
      "8809          1 -0.219178  0.114447  0.042279  0.209603 -0.021991 -0.003300\n",
      "14896         2  0.087369  0.040369 -0.026911 -0.053650  0.029571 -0.007584\n",
      "20246         1  0.079415  0.488975  0.312807  0.045512 -0.047154  0.000411\n",
      "33557         1 -0.004907  0.231600  0.070507  0.039400 -0.030297  0.057259\n",
      "35077         1  0.037159  0.421353  0.138976 -0.097640 -0.015979  0.008691\n",
      "32680         1 -0.001602  0.079625  0.143194 -0.087367 -0.025812  0.019912\n",
      "39162         1 -0.022890 -0.039039 -0.056080 -0.035236 -0.009589 -0.007471\n",
      "29018         0 -0.123396 -0.083161  0.213787 -0.030414  0.141428  0.012340\n",
      "38659         3  0.035711  0.040000 -0.015195  0.049271 -0.013800 -0.005830\n",
      "14414         3 -0.057150 -0.103257  0.454689  0.118826 -0.010359 -0.010912\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_dataset = Ds(data = pca_processed, labels = train_y)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version. Use                 named aggregation instead.\n",
      "\n",
      "    >>> grouper.agg(name_1=func_1, name_2=func_2)\n",
      "\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version. Use                 named aggregation instead.\n",
      "\n",
      "    >>> grouper.agg(name_1=func_1, name_2=func_2)\n",
      "\n",
      "  after removing the cwd from sys.path.\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version. Use                 named aggregation instead.\n",
      "\n",
      "    >>> grouper.agg(name_1=func_1, name_2=func_2)\n",
      "\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  s1        s2     s3  s4  s5         s6        s7         s8  \\\n",
      "client_id                                                                       \n",
      "4          28404.121  1341.802  0.043   2   1  93.000001  0.000001   0.000001   \n",
      "6          15720.739   315.781  0.045  80   1  10.000001  0.000001   0.000001   \n",
      "10         34419.365   654.893  0.045  23   1  65.000001  0.000001   0.000001   \n",
      "11         26789.404  2105.058  0.388  66  88  23.000001  0.000001   2.000001   \n",
      "13         17337.467  1190.322  0.043  83  11  45.000001  0.000001   0.000001   \n",
      "14         26622.629  1167.291  0.043   5   1  39.000001  0.000001   1.000001   \n",
      "17         58337.998  5692.843  0.028  54   1  34.000001  2.000001   9.000001   \n",
      "19         46941.495  2049.338  0.259  26   1  98.000001  0.000001  21.000001   \n",
      "20         79997.006  3213.706  0.043  73  13  10.000001  0.000001   0.000001   \n",
      "25         77245.103  2564.078  0.647  65   1  22.000001  0.000001   4.000001   \n",
      "\n",
      "                 s9       s10  \n",
      "client_id                      \n",
      "4          0.000001  0.000001  \n",
      "6          0.000001  0.000001  \n",
      "10         0.000001  0.000001  \n",
      "11         0.000001  0.000001  \n",
      "13         0.000001  0.000001  \n",
      "14         0.000001  0.000001  \n",
      "17         9.000001  1.000001  \n",
      "19         0.000001  0.000001  \n",
      "20         0.000001  1.000001  \n",
      "25         0.000001  1.000001  \n",
      "           bins        s1        s2        s3        s4        s5        s6  \\\n",
      "client_id                                                                     \n",
      "1046          0  0.007128  0.002887  0.085447  0.026178  0.006024  0.047619   \n",
      "34089         2  0.004184  0.001817  0.006537  0.240838  0.006024  0.135531   \n",
      "34848         1  0.002109  0.000135  0.006537  0.104712  0.006024  0.150183   \n",
      "47076         3  0.001494  0.001214  0.067082  0.115183  0.006024  0.161172   \n",
      "10938         2  0.002494  0.001216  0.011829  0.240838  0.006024  0.003663   \n",
      "42965         1  0.006834  0.000979  0.149572  0.392670  0.006024  0.150183   \n",
      "21594         0  0.004901  0.001277  0.013385  0.167539  0.006024  0.227106   \n",
      "7952          1  0.006509  0.002905  0.006537  0.392670  0.006024  0.172161   \n",
      "33810         0  0.004043  0.002122  0.006537  0.277487  0.006024  0.150183   \n",
      "11061         2  0.002860  0.005940  0.006537  0.026178  0.006024  0.095238   \n",
      "30905         0  0.002225  0.001221  0.014163  0.073298  0.006024  0.073260   \n",
      "29440         3  0.004614  0.001349  0.028327  0.109948  0.006024  0.300366   \n",
      "48434         0  0.008458  0.002940  0.006693  0.471204  0.885542  0.018315   \n",
      "17276         3  0.010568  0.006157  0.092451  0.439791  0.006024  0.172161   \n",
      "34732         3  0.006240  0.003283  0.209961  0.335079  0.006024  0.161172   \n",
      "34843         2  0.005674  0.002772  0.006537  0.109948  0.006024  0.205128   \n",
      "24284         1  0.014540  0.014753  0.067082  0.282723  0.006024  0.223443   \n",
      "2409          2  0.004566  0.001885  0.000000  0.104712  0.006024  0.051282   \n",
      "30746         1  0.038857  0.012774  0.006537  0.115183  0.144578  0.157509   \n",
      "21766         1  0.012833  0.014517  0.216031  0.507853  0.006024  0.128205   \n",
      "8809          1  0.012509  0.007092  0.283424  0.026178  0.006024  0.223443   \n",
      "14896         2  0.003312  0.002275  0.006537  0.335079  0.006024  0.183150   \n",
      "20246         1  0.007039  0.009564  0.228016  0.319372  0.126506  0.699634   \n",
      "33557         1  0.005412  0.001726  0.142412  0.240838  0.006024  0.377289   \n",
      "35077         1  0.009170  0.003493  0.049650  0.282723  0.006024  0.600733   \n",
      "32680         1  0.009478  0.007413  0.006537  0.240838  0.144578  0.293040   \n",
      "39162         1  0.003173  0.001229  0.006537  0.225131  0.006024  0.098901   \n",
      "29018         0  0.022295  0.012403  0.046848  0.115183  0.265060  0.150183   \n",
      "38659         3  0.006175  0.006276  0.108171  0.282723  0.006024  0.168498   \n",
      "14414         3  0.030283  0.023500  0.228016  0.172775  0.481928  0.201465   \n",
      "\n",
      "                 s7        s8        s9  s10  \n",
      "client_id                                     \n",
      "1046       0.000000  0.004950  0.000000  0.0  \n",
      "34089      0.000000  0.000000  0.000000  0.0  \n",
      "34848      0.000000  0.000000  0.000000  0.0  \n",
      "47076      0.000000  0.000000  0.000000  0.0  \n",
      "10938      0.000000  0.000000  0.000000  0.0  \n",
      "42965      0.000000  0.009901  0.000000  0.0  \n",
      "21594      0.000000  0.014851  0.000000  0.0  \n",
      "7952       0.000000  0.004950  0.000000  0.0  \n",
      "33810      0.000000  0.000000  0.017241  0.0  \n",
      "11061      0.000000  0.000000  0.000000  0.0  \n",
      "30905      0.000000  0.019802  0.000000  0.0  \n",
      "29440      0.000000  0.079208  0.000000  0.0  \n",
      "48434      0.000000  0.000000  0.000000  0.0  \n",
      "17276      0.000000  0.000000  0.000000  0.0  \n",
      "34732      0.012658  0.049505  0.000000  0.0  \n",
      "34843      0.000000  0.000000  0.000000  0.0  \n",
      "24284      0.000000  0.000000  0.000000  0.0  \n",
      "2409       0.025316  0.000000  0.000000  0.0  \n",
      "30746      0.000000  0.009901  0.000000  0.0  \n",
      "21766      0.000000  0.103960  0.000000  0.0  \n",
      "8809       0.000000  0.000000  0.000000  0.0  \n",
      "14896      0.012658  0.049505  0.000000  0.0  \n",
      "20246      0.000000  0.004950  0.000000  0.0  \n",
      "33557      0.000000  0.000000  0.060345  0.0  \n",
      "35077      0.012658  0.029703  0.008621  0.0  \n",
      "32680      0.025316  0.000000  0.025862  0.0  \n",
      "39162      0.000000  0.004950  0.000000  0.0  \n",
      "29018      0.012658  0.158416  0.025862  0.0  \n",
      "38659      0.000000  0.004950  0.000000  0.0  \n",
      "14414      0.000000  0.009901  0.000000  0.0  \n"
     ]
    }
   ],
   "source": [
    "train_y = ds.get_data('train_target')\n",
    "#print(train_y.head())\n",
    "\n",
    "train_x = ds.get_data('train_x')\n",
    "\n",
    "#train_y.set_index('client_id', inplace=True)\n",
    "data = prepare_featured_data_v2(train_x)\n",
    "print(data.head(10))\n",
    "\n",
    "processed = normalize([\"s1\", \"s2\", \"s3\", \"s4\", \"s5\", \"s6\", \"s7\", \"s8\", \"s9\", \"s10\"], data)\n",
    "\n",
    "train_dataset = Ds(data = processed, labels = train_y)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "is_cuda = torch.cuda.is_available()\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\"),\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(device(type='cuda'),)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 \tLoss: 1.211276\n",
      "Train Epoch: 2 \tLoss: 1.102562\n",
      "Train Epoch: 3 \tLoss: 1.557207\n",
      "Train Epoch: 4 \tLoss: 1.276192\n",
      "Train Epoch: 5 \tLoss: 1.266304\n",
      "Train Epoch: 6 \tLoss: 1.218385\n",
      "Train Epoch: 7 \tLoss: 1.504468\n",
      "Train Epoch: 8 \tLoss: 1.044336\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "print(device)\n",
    "network = Net().cuda()\n",
    "optimizer = optim.Adam(network.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(1, 9):\n",
    "    network.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        #if batch_idx > 2460:\n",
    "            #output = network(data.cuda())\n",
    "            #pred = output.data.max(1, keepdim=True)[1]\n",
    "            #print('ACURACY: {}'.format((pred.flatten() == target).sum()))\n",
    "       # else:\n",
    "            optimizer.zero_grad()\n",
    "            output = network(data.cuda())\n",
    "            loss = F.cross_entropy(output, target.cuda()).cuda()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    print('Train Epoch: {} \\tLoss: {:.6f}'.format(\n",
    "            epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'res_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a6d0dc4cfdfb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mres_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'large_num'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'res_df' is not defined"
     ]
    }
   ],
   "source": [
    "print(len(res_df[res_df['large_num']>0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24679760888129804"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier(n_estimators=10, random_state=0)\n",
    "\n",
    "# похоже где-то ошибка, возможно, где криво джоинится по айди клиента. Либо фичи полное говно\n",
    "clf.fit(processed[[\"s1\", \"s2\", \"s3\", \"s4\", \"s5\"]].values,train_y['bins'].values)\n",
    "clf.score(valid_x[[\"s1\", \"s2\", \"s3\", \"s4\", \"s5\"]].values,valid_y['bins'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        28571\n",
      "1        27046\n",
      "2        13240\n",
      "3        19974\n",
      "4        10505\n",
      "5        36581\n",
      "6        13137\n",
      "7        29069\n",
      "8        14334\n",
      "9         7432\n",
      "10       44221\n",
      "11       40799\n",
      "12       36456\n",
      "13         818\n",
      "14       35103\n",
      "15       48997\n",
      "16        4975\n",
      "17        4013\n",
      "18       30955\n",
      "19       26778\n",
      "20         709\n",
      "21        9410\n",
      "22       15212\n",
      "23       11347\n",
      "24         766\n",
      "25          55\n",
      "26        2493\n",
      "27       46885\n",
      "28       39401\n",
      "29        8934\n",
      "         ...  \n",
      "19970     5048\n",
      "19971    21095\n",
      "19972    29891\n",
      "19973     6069\n",
      "19974    39294\n",
      "19975    41915\n",
      "19976    44830\n",
      "19977    44923\n",
      "19978    25431\n",
      "19979    27672\n",
      "19980    21382\n",
      "19981     6221\n",
      "19982    30173\n",
      "19983    28339\n",
      "19984    24920\n",
      "19985    17978\n",
      "19986    16100\n",
      "19987    41833\n",
      "19988    26651\n",
      "19989    37973\n",
      "19990    14102\n",
      "19991    26308\n",
      "19992      910\n",
      "19993    48964\n",
      "19994    13582\n",
      "19995     2565\n",
      "19996    31255\n",
      "19997    31539\n",
      "19998     4288\n",
      "19999    15323\n",
      "Name: client_id, Length: 20000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "test_y = ds.get_data('test_target')\n",
    "print(ds.get_data('test_target').iloc[:, 0])\n",
    "#test_y.set_index('client_id', inplace=True)\n",
    "#test_x = ds.get_data('test_x')\n",
    "\n",
    "#test_processed = normalize([\"amount_rur\", \"max\", \"tran_num_mean\", \"small_num\", \"large_num\"], prepare_featured_data(test_x))\n",
    "#clf.score(test_processed[[\"amount_rur\", \"max\", \"tran_num_mean\", \"small_num\", \"large_num\"]].values,test_y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: [28571, 27046, 13240, 19974, 10505]\n"
     ]
    }
   ],
   "source": [
    "print(test_y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version. Use                 named aggregation instead.\n",
      "\n",
      "    >>> grouper.agg(name_1=func_1, name_2=func_2)\n",
      "\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version. Use                 named aggregation instead.\n",
      "\n",
      "    >>> grouper.agg(name_1=func_1, name_2=func_2)\n",
      "\n",
      "  after removing the cwd from sys.path.\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version. Use                 named aggregation instead.\n",
      "\n",
      "    >>> grouper.agg(name_1=func_1, name_2=func_2)\n",
      "\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           bins        s1        s2        s3        s4        s5   s6   s7  \\\n",
      "client_id                                                                     \n",
      "24662         2  0.014923  0.004839  0.015675  0.284211  0.066298  0.0  0.0   \n",
      "47651         3  0.020765  0.003163  0.088254  0.147368  0.005525  0.0  0.0   \n",
      "36224         2  0.004771  0.002299  0.092549  0.378947  0.005525  0.0  0.0   \n",
      "21691         1  0.018916  0.017944  0.184883  0.173684  0.071823  0.0  0.0   \n",
      "29957         3  0.025960  0.015075  0.009019  0.089474  0.011050  0.0  0.0   \n",
      "30401         2  0.011060  0.002129  0.092549  0.284211  0.005525  0.0  0.0   \n",
      "15639         0  0.018530  0.002320  0.068499  0.242105  0.005525  0.0  0.0   \n",
      "28539         1  0.016628  0.002953  0.008804  0.378947  0.005525  0.0  0.0   \n",
      "39868         3  0.038876  0.010590  0.009019  0.531579  0.132597  0.0  0.0   \n",
      "48975         0  0.038527  0.008853  0.323599  0.068421  0.005525  0.0  0.0   \n",
      "26720         0  0.022271  0.006457  0.006657  0.236842  0.011050  0.0  0.0   \n",
      "35206         0  0.030000  0.009648  0.009019  0.242105  0.005525  0.0  0.0   \n",
      "11869         0  0.019555  0.004590  0.092549  0.589474  0.027624  0.0  0.0   \n",
      "24916         0  0.027182  0.009351  0.009448  0.426316  0.005525  0.0  0.0   \n",
      "39277         2  0.011517  0.009650  0.005154  0.121053  0.005525  0.0  0.0   \n",
      "12125         3  0.032492  0.015992  0.009019  0.242105  0.005525  0.0  0.0   \n",
      "48704         2  0.007849  0.004080  0.009019  0.394737  0.005525  0.0  0.0   \n",
      "7536          3  0.016417  0.002400  0.009448  0.147368  0.005525  0.0  0.0   \n",
      "8535          3  0.140312  0.022291  0.018252  0.331579  0.132597  0.0  0.0   \n",
      "24212         2  0.014773  0.001404  0.009663  0.036842  0.005525  0.0  0.0   \n",
      "2795          3  0.050127  0.025956  0.323814  0.026316  0.005525  0.0  0.0   \n",
      "7286          1  0.046357  0.069066  0.147949  0.068421  0.027624  0.0  0.0   \n",
      "49487         3  0.022103  0.011983  0.211510  0.421053  0.005525  0.0  0.0   \n",
      "30850         0  0.023650  0.009871  0.009019  0.289474  0.005525  0.0  0.0   \n",
      "23559         3  0.012779  0.016035  0.009019  0.105263  0.005525  0.0  0.0   \n",
      "36187         1  0.021808  0.004322  0.046597  0.026316  0.005525  0.0  0.0   \n",
      "15108         2  0.015531  0.005124  0.009019  0.026316  0.005525  0.0  0.0   \n",
      "13861         3  0.036511  0.006326  0.009448  0.263158  0.005525  0.0  0.0   \n",
      "45062         3  0.013420  0.007223  0.147305  0.510526  0.005525  0.0  0.0   \n",
      "13648         2  0.019687  0.008563  0.000215  0.426316  0.005525  0.0  0.0   \n",
      "\n",
      "            s8   s9  s10  \n",
      "client_id                 \n",
      "24662      0.0  0.0  0.0  \n",
      "47651      0.0  0.0  0.0  \n",
      "36224      0.0  0.0  0.0  \n",
      "21691      0.0  0.0  0.0  \n",
      "29957      0.0  0.0  0.0  \n",
      "30401      0.0  0.0  0.0  \n",
      "15639      0.0  0.0  0.0  \n",
      "28539      0.0  0.0  0.0  \n",
      "39868      0.0  0.0  0.0  \n",
      "48975      0.0  0.0  0.0  \n",
      "26720      0.0  0.0  0.0  \n",
      "35206      0.0  0.0  0.0  \n",
      "11869      0.0  0.0  0.0  \n",
      "24916      0.0  0.0  0.0  \n",
      "39277      0.0  0.0  0.0  \n",
      "12125      0.0  0.0  0.0  \n",
      "48704      0.0  0.0  0.0  \n",
      "7536       0.0  0.0  0.0  \n",
      "8535       0.0  0.0  0.0  \n",
      "24212      0.0  0.0  0.0  \n",
      "2795       0.0  0.0  0.0  \n",
      "7286       0.0  0.0  0.0  \n",
      "49487      0.0  0.0  0.0  \n",
      "30850      0.0  0.0  0.0  \n",
      "23559      0.0  0.0  0.0  \n",
      "36187      0.0  0.0  0.0  \n",
      "15108      0.0  0.0  0.0  \n",
      "13861      0.0  0.0  0.0  \n",
      "45062      0.0  0.0  0.0  \n",
      "13648      0.0  0.0  0.0  \n"
     ]
    }
   ],
   "source": [
    "valid_y = ds.get_data('valid_target')\n",
    "#valid_y.set_index('client_id', inplace = True)\n",
    "\n",
    "valid_x = ds.get_data('valid_x')\n",
    "valid_x = normalize([\"s1\", \"s2\", \"s3\", \"s4\", \"s5\", \"s6\", \"s7\", \"s8\", \"s9\", \"s10\"], prepare_featured_data_v2(valid_x))\n",
    "\n",
    "valid_dataset = Ds(data = valid_x, labels = valid_y)\n",
    "\n",
    "total = len(valid_dataset)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=total)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACURACY: 2367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "def validateNet(net):\n",
    "    r, idd = iter(valid_loader).next()\n",
    "    output = net(r.cuda()).cpu()\n",
    "    \n",
    "    pred = output.data.max(1, keepdim=True)[1]\n",
    "   # print(pred)\n",
    "    print('ACURACY: {}'.format((pred.flatten() == idd).sum()))\n",
    "    \n",
    "validateNet(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5855\n"
     ]
    }
   ],
   "source": [
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
